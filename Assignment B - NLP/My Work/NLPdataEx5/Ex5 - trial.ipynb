{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('data_senti_analyze.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = f1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose is beautiful.\n",
      "Place is nasty to stay.\n",
      "This is the beauty of this technique.\n",
      "Concept is explained beautifully in this book.\n",
      "He annoyed me.\n",
      "Its the supreme place to stay.\n",
      "I hate this place.\n",
      "Dont annoy the customer.\n",
      "He has given nasty comments about his stay.\n",
      "Dessert is awesome.\n",
      "Your gift is wonderful.\n"
     ]
    }
   ],
   "source": [
    "print input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_list = input_data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_words_dict = f2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_words=[\"hate\",\"hatred\",\"annoyed\",\"annoy\",\"annoyingly\",\"nasty\"]\n",
      "pos_words=[\"nice\",\"excellent\",\"good\",\"wonderful\",\"best\",\"better\",\"awesome\",\"beautiful\",\"beauty\",\"beautifully\",\"supreme\"]\n"
     ]
    }
   ],
   "source": [
    "print pos_neg_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_words_dict = pos_neg_words_dict.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg_words=[\"hate\",\"hatred\",\"annoyed\",\"annoy\",\"annoyingly\",\"nasty\"]', 'pos_words=[\"nice\",\"excellent\",\"good\",\"wonderful\",\"best\",\"better\",\"awesome\",\"beautiful\",\"beauty\",\"beautifully\",\"supreme\"]']\n"
     ]
    }
   ],
   "source": [
    "print pos_neg_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_words': '[\"nice\",\"excellent\",\"good\",\"wonderful\",\"best\",\"better\",\"awesome\",\"beautiful\",\"beauty\",\"beautifully\",\"supreme\"]', 'neg_words': '[\"hate\",\"hatred\",\"annoyed\",\"annoy\",\"annoyingly\",\"nasty\"]'}\n"
     ]
    }
   ],
   "source": [
    "for key_value in pos_neg_words_dict:\n",
    "    key_value = key_value.split('=')\n",
    "    words_dict[key_value[0]] = key_value[1]\n",
    "    \n",
    "print words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 3] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')] # remove stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rose', 'beautiful']\n",
      "['place', 'nasty', 'stay']\n",
      "['beauty', 'technique']\n",
      "['concept', 'explained', 'beautifully', 'book']\n",
      "['annoyed']\n",
      "['supreme', 'place', 'stay']\n",
      "['hate', 'place']\n",
      "['dont', 'annoy', 'customer']\n",
      "[u'ha', 'given', 'nasty', u'comment', 'stay']\n",
      "['dessert', 'awesome']\n",
      "['gift', 'wonderful']\n"
     ]
    }
   ],
   "source": [
    "for sent in input_data_list:\n",
    "    print my_tokenizer(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_words': '[\"nice\",\"excellent\",\"good\",\"wonderful\",\"best\",\"better\",\"awesome\",\"beautiful\",\"beauty\",\"beautifully\",\"supreme\"]', 'neg_words': '[\"hate\",\"hatred\",\"annoyed\",\"annoy\",\"annoyingly\",\"nasty\"]'}\n"
     ]
    }
   ],
   "source": [
    "print words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words, list_of_words):\n",
    "    return ([True for word in tokenized_words if word in list_of_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentiment = {}\n",
    "negative_sentiment = {}\n",
    "positive_score = 0\n",
    "negative_score = 0\n",
    "\n",
    "for sent in input_data_list:\n",
    "    tokens = my_tokenizer(sent)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in words_dict['pos_words']:\n",
    "            positive_score += 1\n",
    "        \n",
    "        elif token in words_dict['neg_words']:\n",
    "            negative_score += 1\n",
    "            \n",
    "        if((positive_score - negative_score)>=0):\n",
    "            positive_sentiment[sent] = positive_score - negative_score\n",
    "        \n",
    "        else:\n",
    "            negative_sentiment[sent] = positive_score - negative_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'This is the beauty of this technique.': 1, 'He annoyed me.': 1, 'I hate this place.': 1, 'Rose is beautiful.': 1, 'Place is nasty to stay.': 0, 'Concept is explained beautifully in this book.': 2, 'Dont annoy the customer.': 0, 'Your gift is wonderful.': 0, 'Its the supreme place to stay.': 2}\n",
      "{'Dessert is awesome.': -1, 'Your gift is wonderful.': -1, 'He has given nasty comments about his stay.': -2}\n"
     ]
    }
   ],
   "source": [
    "print positive_sentiment \n",
    "print negative_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentiment = {}\n",
    "negative_sentiment = {}\n",
    "\n",
    "for sent in input_data_list:\n",
    "    tokens = my_tokenizer(sent)\n",
    "\n",
    "    if bag_of_words(tokens, words_dict['pos_words']):\n",
    "        positive_sentiment[sent] = 'Positive Sentiment'\n",
    "    \n",
    "    else:\n",
    "        negative_sentiment[sent] = 'Negative Sentiment'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dessert is awesome.': 'Positive Sentiment', 'This is the beauty of this technique.': 'Positive Sentiment', 'Rose is beautiful.': 'Positive Sentiment', 'Concept is explained beautifully in this book.': 'Positive Sentiment', 'Your gift is wonderful.': 'Positive Sentiment', 'Its the supreme place to stay.': 'Positive Sentiment'}\n",
      "{'He annoyed me.': 'Negative Sentiment', 'Dont annoy the customer.': 'Negative Sentiment', 'I hate this place.': 'Negative Sentiment', 'He has given nasty comments about his stay.': 'Negative Sentiment', 'Place is nasty to stay.': 'Negative Sentiment'}\n"
     ]
    }
   ],
   "source": [
    "print positive_sentiment \n",
    "print negative_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
