{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anilkumar.ganesh@wipro.com\n",
    "import sklearn\n",
    "# Import all of the scikit learn stuff\n",
    "#from __future__ import print_function\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# Suppress warnings from pandas library\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"pandas\", lineno=570)\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "example = [\"Machine learning is very fun\", \"Python is very, very nice\", \"Statistics is nice, too\", \"Data science is fun\",\n",
    "\"Python is great for machine learning\", \"I like Cricket\", \"Cricket is great to watch\"]\n",
    "vectorizer = CountVectorizer(min_df = 1, stop_words = 'english')\n",
    "dtm = vectorizer.fit_transform(example)\n",
    "print(pd.DataFrame(dtm.toarray(),index=example,columns=vectorizer.get_feature_names()).head(10))\n",
    "\n",
    "# Get words that correspond to each column\n",
    "vectorizer.get_feature_names()\n",
    "\n",
    "# Fit LSA. Use algorithm = “randomized” for large datasets\n",
    "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(dtm)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n",
    "\n",
    "print(pd.DataFrame(lsa.components_,index = [\"component_1\",\"component_2\"],columns = vectorizer.get_feature_names()))\n",
    "print(pd.DataFrame(dtm_lsa, index = example, columns = [\"component_1\",\"component_2\"]))\n",
    "\n",
    "xs = [w[0] for w in dtm_lsa]\n",
    "ys = [w[1] for w in dtm_lsa]\n",
    "print (xs, ys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"@@@@@@@@@@@@@\")\n",
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(numpy.asmatrix(dtm_lsa) * numpy.asmatrix(dtm_lsa).T)\n",
    "print (pd.DataFrame(similarity,index=example, columns=example).head(10))\n",
    "\n",
    "print (\"#################\")\n",
    "#%pylab inline\n",
    "import pylab\n",
    "pylab.interactive(True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.scatter(xs,ys)\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.title('Plot of points against LSA principal components')\n",
    "plt.show(1)\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "ax = plt.gca()\n",
    "ax.quiver(0,0,xs,ys,angles='xy',scale_units='xy',scale=1, linewidth = .01)\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.title('Plot of points against LSA principal components')\n",
    "plt.show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
